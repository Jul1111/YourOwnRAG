# YourOwnRAG - Your Own Retrieval Augmented Generation Chatbot

Un chatbot alimentÃ© par **Retrieval Augmented Generation (RAG)** qui utilise une base de donnÃ©es vectorielle pour rÃ©pondre aux questions en se basant sur des documents personnalisÃ©s.

## ğŸ¯ FonctionnalitÃ©s

- **Chatbot Interactif** : Pose des questions et reÃ§ois des rÃ©ponses en temps rÃ©el
- **Base de DonnÃ©es Vectorielle** : Indexation intelligent des documents via embeddings
- **Recherche SÃ©mantique** : Retrouve les chunks les plus pertinents grÃ¢ce Ã  la similaritÃ© cosinus
- **Support Multi-Format** : Texte brut, code source, etc.
- **ModÃ¨les Open Source** : Utilise Ollama avec des modÃ¨les lÃ©gers et efficaces

## ğŸ—ï¸ Architecture

```
YourOwnRAG/
â”œâ”€â”€ main.py                          # Point d'entrÃ©e principal
â”œâ”€â”€ requirements.txt                 # DÃ©pendances
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ loadingDataset.py           # Charge les donnÃ©es depuis des fichiers
â”‚   â”œâ”€â”€ implementVectorDB.py         # Gestion de la base vectorielle
â”‚   â””â”€â”€ retrievalFunction.py         # Recherche sÃ©mantique
â”œâ”€â”€ tmp/
â”‚   â””â”€â”€ cat-facts.txt                # DonnÃ©es d'exemple
â””â”€â”€ vector_db/                       # Stockage des embeddings
```

## ğŸ“¦ Installation

### 1. Cloner le repo

```bash
git clone https://github.com/Jul1111/YourOwnRAG.git
cd YourOwnRAG/Version1
```

### 2. CrÃ©er un environnement virtuel

```bash
python3 -m venv .venv
source .venv/bin/activate  # macOS/Linux
# ou
.venv\Scripts\activate  # Windows
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Configurer Ollama

Le projet utilise [Ollama](https://ollama.ai/) pour les embeddings et le modÃ¨le de langage.

```bash
# Installer Ollama depuis https://ollama.ai/
# Puis tÃ©lÃ©charger les modÃ¨les nÃ©cessaires
ollama pull nomic-embed-text      # Pour les embeddings
ollama pull llama2                 # Pour le modÃ¨le de langage
```

## ğŸš€ Utilisation

### Lancer le chatbot

```bash
python main.py
```

### Exemple d'interaction

```
==================================================
Chatbot is ready! Type "exit" to quit.
==================================================

You: Quelle est l'histoire des clowders?

Retrieved knowledge:
 - (similarity: 0.92) Un clowder est un groupe de chats...
 - (similarity: 0.87) Les clowders sont souvent observÃ©s...

Bot: Un clowder est un groupe de chats qui vivent ensemble...

You: exit
Goodbye!
```

## ğŸ”§ Configuration

### Modifier la source de donnÃ©es

Ã‰ditez `main.py` pour charger vos propres documents :

```python
dataset = load_dataset('chemin/vers/votre/fichier.txt')
```

### Ajuster les paramÃ¨tres de RAG

- **Taille des chunks** : Modifiez `chunk_size` dans `implementVectorDB.py`
- **SimilaritÃ© minimale** : Ajustez `top_n` dans `main.py`
- **ModÃ¨les** : Changez `EMBEDDING_MODEL` ou `LANGUAGE_MODEL`

## ğŸ“š Modules Principaux

### `implementVectorDB.py`

- CrÃ©e la base de donnÃ©es vectorielle avec embeddings
- GÃ¨re le dÃ©coupage de texte adaptÃ© (code source vs texte brut)
- `create_vector_db_from_dataset()` : Indexe tous les chunks

### `retrievalFunction.py`

- Calcule la similaritÃ© cosinus entre embeddings
- `retrieve(query, top_n=3)` : Retrouve les chunks pertinents

### `loadingDataset.py`

- `load_dataset(filename)` : Charge les donnÃ©es depuis un fichier texte

## ğŸ’¡ Comment fonctionne le RAG

1. **Indexation** : Les documents sont divisÃ©s en chunks et convertis en embeddings
2. **Recherche** : La question est transformÃ©e en embedding
3. **SimilaritÃ©** : On trouve les chunks les plus proches sÃ©mantiquement
4. **Contexte** : Ces chunks sont passÃ©s au modÃ¨le de langage
5. **GÃ©nÃ©ration** : Le modÃ¨le gÃ©nÃ¨re une rÃ©ponse basÃ©e sur le contexte

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Ollama** : ModÃ¨les LLM open source
- **LangChain** : Splitting de texte et orchestration
- **Python** : Langage principal
- **Embeddings** : BGE (Base General Embedding)

## ğŸ“ Roadmap

- [ ] Support des fichiers PDF
- [ ] Interface web (Streamlit/FastAPI)
- [ ] Persistance de la base vectorielle
- [ ] Fine-tuning sur domaines spÃ©cifiques
- [ ] Support du multi-langue

## ğŸ“„ Licence

MIT License - Voir LICENSE pour plus de dÃ©tails

## âœ¨ Contributions

Les contributions sont bienvenues ! Ouvre une issue ou un PR pour proposer des amÃ©liorations.
